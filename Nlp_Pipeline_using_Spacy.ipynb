{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsJgbblC7z4bSs/iEALE2L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adnan855570/Natural_language_Processing/blob/main/Nlp_Pipeline_using_Spacy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdVolr7fGrxU"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.blank(\"en\")\n",
        "\n",
        "doc = nlp(\"Captain ameria is part of Avengers\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDns9DrAG2Nz",
        "outputId": "c12bc3c6-f56a-403f-9b73-7cf9d994a241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain\n",
            "ameria\n",
            "is\n",
            "part\n",
            "of\n",
            "Avengers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cT3hXSq6HMht",
        "outputId": "f9b9fc95-9a32-47bc-dd56-c4d8e62a3804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "SuxMHX7bJTAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmcjZInAMbtp",
        "outputId": "d1b48b14-7224-4b1b-db39-bbfa48a0699d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8TQefNeMjyk",
        "outputId": "adb2dd20-c8a5-486c-cec4-4c26c23e2676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x78fd158dad40>),\n",
              " ('tagger', <spacy.pipeline.tagger.Tagger at 0x78fd158db0a0>),\n",
              " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x78fda8e84350>),\n",
              " ('attribute_ruler',\n",
              "  <spacy.pipeline.attributeruler.AttributeRuler at 0x78fd15607c40>),\n",
              " ('lemmatizer',\n",
              "  <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x78fd155f3f80>),\n",
              " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x78fda8e86650>)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Captain america is part of Avengers\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token, \"|\" , token.pos_, \"|\", token.lemma_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jykrvb7DM6L5",
        "outputId": "77f8bc8c-fa89-4eb2-e735-f49563b8b4e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Captain | PROPN | Captain\n",
            "america | PROPN | america\n",
            "is | AUX | be\n",
            "part | NOUN | part\n",
            "of | ADP | of\n",
            "Avengers | PROPN | Avengers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Name Entity Recognition"
      ],
      "metadata": {
        "id": "qoHCd3jzCnoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Tesla is going to aquire twitter for $4 billion\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, \"|\", ent.label_, \"|\", spacy.explain(ent.label_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srtjc5gNCsY8",
        "outputId": "cb005e90-2bbd-410c-8cf5-f9aca79248ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla | ORG | Companies, agencies, institutions, etc.\n",
            "$4 billion | MONEY | Monetary values, including unit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For rendering or displaying it nicely"
      ],
      "metadata": {
        "id": "i7dQXYx3FdGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(doc , style=\"ent\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "QZvXbA5GFkb5",
        "outputId": "01f3397d-9b82-4e1f-eb4f-8e0321312a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tesla\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is going to aquire twitter for \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    $4 billion\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spacy Language Processing Pipelines: Exercises"
      ],
      "metadata": {
        "id": "Do0Gfk8kSJu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing necessary libraries\n",
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")  #creating an object and loading the pre-trained model for \"English\""
      ],
      "metadata": {
        "id": "DKdoPrhnSK0p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excersie: 1\n",
        "Get all the proper nouns from a given text in a list and also count how many of them.\n",
        "# Proper Noun means a noun that names a particular person, place, or thing."
      ],
      "metadata": {
        "id": "sBk-FYxFSN8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''Ravi and Raju are the best friends from school days.They wanted to go for a world tour and\n",
        "visit famous cities like Paris, London, Dubai, Rome etc and also they called their another friend Mohan to take part of this world tour.\n",
        "They started their journey from Hyderabad and spent next 3 months travelling all the wonderful cities in the world and cherish a happy moments!\n",
        "'''\n",
        "\n",
        "# https://spacy.io/usage/linguistic-features\n",
        "\n",
        "#creating the nlp object\n",
        "doc = nlp(text)\n",
        "\n",
        "# Extract nouns from the processed text\n",
        "nouns = [token.text for token in doc if token.pos_ == \"NOUN\"]\n",
        "\n",
        "# Print the extracted nouns\n",
        "print(\"Nouns:\", nouns)\n",
        "\n",
        "# Extract nouns and count their occurrences\n",
        "noun_counter = Counter(token.text for token in doc if token.pos_ == \"NOUN\")\n",
        "\n",
        "# Print the noun count\n",
        "print(\"Noun Count:\", noun_counter)"
      ],
      "metadata": {
        "id": "SYxdgF-4SRRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a43db7-9bc2-4651-a112-0a6a6fee80db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nouns: ['Ravi', 'friends', 'school', 'days', 'world', 'tour', 'cities', 'friend', 'part', 'world', 'tour', 'journey', 'months', 'cities', 'world', 'moments']\n",
            "Noun Count: Counter({'world': 3, 'tour': 2, 'cities': 2, 'Ravi': 1, 'friends': 1, 'school': 1, 'days': 1, 'friend': 1, 'part': 1, 'journey': 1, 'months': 1, 'moments': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excersie: 2\n",
        "Get all companies names from a given text and also the count of them.\n",
        "# Hint: Use the spacy ner functionality"
      ],
      "metadata": {
        "id": "nnSwYS8GSTck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = '''The Top 5 companies in USA are Tesla, Walmart, Amazon, Microsoft, Google and the top 5 companies in\n",
        "India are Infosys, Reliance, HDFC Bank, Hindustan Unilever and Bharti Airtel'''\n",
        "\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "# Extract company names\n",
        "company_names = [entity.text for entity in doc.ents if entity.label_ == \"ORG\"]\n",
        "\n",
        "# Print the extracted company names\n",
        "print(\"Company Names:\", company_names)"
      ],
      "metadata": {
        "id": "4EPOxNaCSXj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e41b3eb2-78c6-4327-a047-c6b9e77dd7eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Company Names: ['Tesla', 'Walmart', 'Amazon', 'Microsoft', 'Google', 'Infosys', 'Reliance', 'HDFC Bank', 'Hindustan Unilever', 'Bharti']\n"
          ]
        }
      ]
    }
  ]
}